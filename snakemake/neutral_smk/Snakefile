import os
from glob import glob
from snakemake.checkpoints import Checkpoint
import yaml

# Load configuration
configfile: "config.yaml"

# Functions
def get_genome(genome_in):
    name=os.path.splitext(os.path.basename(genome_in))[0]
    return name
CHROMS=config["chrom_targets"]
TREE_TOPOLOGY = config["tree_topology"]
##################################################

rule all:
    input:
        "snakemake.done"

rule get_sizes:
    message: "take {input.genome} and generate chromosome length file for input into rule get_random"
    input:
        genome=config["genome_fasta"]
    conda:
        "envs/biopython.yaml"
    log:
        "logs/get_sizes.log"
    output:
         sizes=get_genome(config["genome_fasta"])+".chrom.sizes"
    shell:
        """
        samtools faidx {input.genome}
        cut -f1,2 {input.genome}.fai > {output.sizes}
        """

rule bed_random:
    message: "randomly window the {input.chrom_sizes} using the output of 'get_sizes', sort the resulting file, and adjust 1-indexed positions to 0-indexed positions"
    input:
        chrom_sizes=get_genome(config["genome_fasta"])+".chrom.sizes"
    threads: 24
    conda:
        "envs/biopython.yaml"
    log:
        "logs/{chr}.bed_random.log"
    output:
        "features/{chr}.feat.bed"
    shell:
        """
        mkdir -p features/
        bedtools random -n 500 -l 300 -g {input.chrom_sizes} > random.bed
        sort -k1,1 -k2,2n random.bed > random.sorted.bed
        grep -w "{wildcards.chr}" "random.sorted.bed" | awk '{{print $1 "\\t" $2-1 "\\t" $3 }}' | sort -k1,1 -k2,2 -V > "features/{wildcards.chr}.feat.bed"
        """

rule msa_split:
    message: "split .maf files into windowed regions of features according to the *.feat.bed files."
    input:
        bed_feats="features/{chrom}.feat.bed",
        mask_maf=config["maf_pattern"],
        mask_fa=config["fa_pattern"]
    conda:
        "envs/biopython.yaml"
    log:
        "logs/{chrom}.msa_split.log"
    output:
        "pruned_neutral/{chrom}/done.txt"
    shell:
        """
        mkdir -p pruned_neutral/
        msa_split {input.mask_maf} --refseq {input.mask_fa} --gap-strip ANY -q \
        --in-format MAF --features {input.bed_feats} --for-features --out-root pruned_neutral/{wildcards.chrom}
        touch {output}
        """

rule pruning:
    message: "take the generated split alignment files and prune sequences that are not the correct size (300bp windows)."
    input:
        expand("pruned_neutral/{chrom}/done.txt", chrom=config["chrom_targets"])
    output:
        list="all.pruned.list"
    log:
        "logs/prune_all.log"
    shell:
        """
        echo "Searching for FASTA files to prune..." > {log}
        for file in $(find pruned_neutral/ -maxdepth 2 -type f -name '*.fa' ! -name '*.prunned'); do
            echo "Processing $file" >> {log}
            echo "$file" > temp.list
            python scripts/prunning.py temp.list >> {log} 2>&1
        done
        rm -f temp.list
        echo "Collecting all prunned files..." >> {log}
        find pruned_neutral/ -maxdepth 2 -type f -name '*.fa.prunned' > {output.list} 2>> {log}
        """

checkpoint filtering:
    message: "remove any pruned alignment that has high N or ambiguous sequence content."
    input:
        pruned_list="all.pruned.list"
    output:
        good="goodalignments.txt",
        ambiguous="ambiguous.txt",
        dir=directory("good_alignments")
    conda:
        "envs/biopython.yaml"
    log:
        "logs/filter_alignments.log"
    shell:
        """
        python3 scripts/filtering_p3.py {input.pruned_list} > {log} 2>&1
        mkdir -p {output.dir} 
        for file in `cat {output.good}`; do cp "$file" {output.dir} ; done
        """

rule PhyloFit:
    message: "compute the substitution rate among each node and tip of the multi-alignment tree using PhyloFit."
    input:
        fa="good_alignments/{chr}.fa.prunned",
    output:
        mod="MODELS_HKY85/{chr}.mod"
    conda:
        "envs/biopython.yaml"
    log:
        "logs/phylofit.{chr}.log"
    shell:
        """
        mkdir -p MODELS_HKY85/
        phyloFit {input.fa} --tree "{TREE_TOPOLOGY}" -i FASTA --subst-mod HKY85 --out-root MODELS_HKY85/{wildcards.chr} > {log} 2>&1
        """

def get_chrs(wildcards):
    checkpoint_output = checkpoints.filtering.get(**wildcards).output[0]
    with open(checkpoint_output, "r") as f:
        return[line.strip().replace("pruned_neutral/", "").replace(".fa.prunned","") for line in f if line.strip()]

rule aggregate:
    input:
        good="goodalignments.txt",
        phylofit_out=lambda wc: expand("MODELS_HKY85/{chrs}.mod", chrs=get_chrs(wc))
    output:
        table="output.hky85.neutral.txt"
    shell: 
        """
        for file in {input.phylofit_out}; do
            grep -H 'TREE:' $file
        done > {output.table}
        """

rule cleanup:
    message: "clean up files only after PhyloFit has completed."
    input:
        table="output.hky85.neutral.txt"
    output:
        "snakemake.done"
    shell:
        """
        mkdir -p intermediate_files/
        mv -f all.pruned.list ambiguous.txt features/ *.chrom.sizes good_alignments/ random.bed random.sorted.bed goodalignments.txt logs/ pruned_neutral/ MODELS_HKY85/ intermediate_files/
        ls > snakemake.done
        """
