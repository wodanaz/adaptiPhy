import os
from pathlib import Path

configfile: "config.yaml"

# =============================================================================
# CONFIGURATION
# =============================================================================
TREE_TOPOLOGY = config["tree_topology"]  # your input tree
CHROMS = config["chrom_targets"] # from chromosome/scaffold id on config.yaml
if isinstance(CHROMS, str):
    CHROMS = [CHROMS]
GENOME = config["genome_fasta"] # YOur reference genome
GENOME_NAME = os.path.splitext(os.path.basename(GENOME))[0] by input id
CHROM_SIZES = f"{GENOME_NAME}.chrom.sizes" # by input id
TOTAL_WINDOWS = config["total_windows"] # this can be any number > 1 Million. For the primate alignment. we optained nearly 30000 neutral proxy after the pipeline finish running. Be aware this depends upon genome qulity and how well the species align in your genome-wide alignment.
WINDOW_SIZE = config["window_size"] # define the window size. we define 300 bp as the minimal size.
MIN_BASES = config["min_bases"] # define the minimal number of bases that are necesarry to pass as a good alignment.
BATCH_SIZE = config["batch_size"] # DEfine equaly sized batches to run phylofit. Find a relative number based on your cores available and search size, in example 2 million alignments of 300 bp are processed in 2 hours in a hpc system.

# FINAL TARGET
rule all:
    input:
        "snakemake.done"

# 1. Get chromosome sizes
rule get_sizes:
    input:
        genome = GENOME
    output:
        sizes = CHROM_SIZES
    conda:
        "envs/biopython.yaml"
    log:
        "logs/get_sizes.log"
    shell:
        """
        mkdir -p logs
        samtools faidx {input.genome}
        cut -f1,2 {input.genome}.fai > {output.sizes} 2> {log}
        """

# 2. Random windows
rule bed_random:
    input:
        chrom_sizes = CHROM_SIZES
    output:
        "random.sorted.bed"
    threads: 24
    conda:
        "envs/biopython.yaml"
    log:
        "logs/bed_random.log"
    shell:
        """
        mkdir -p features logs
        bedtools random -n {TOTAL_WINDOWS} -l {WINDOW_SIZE} -g {input} > random.bed
        sort -k1,1 -k2,2n random.bed > {output} 2> {log}
        rm -f random.bed
        """

# 3. Split by chromosome
rule individual_feats:
    input:
        "random.sorted.bed"
    output:
        "features/{chrom}.feat.bed"
    conda:
        "envs/biopython.yaml"
    log:
        "logs/individual_feats/{chrom}.log"
    resources:
        mem_mb = 1000
    shell:
        r"""
        mkdir -p features logs/individual_feats
        grep -E '^{wildcards.chrom}\b' {input} |
        awk -v OFS='\t' '{{print $1, $2-1, $3}}' |
        sort -k2,2n > {output} 2> {log}
        """

# 4. Extract alignments — writes to pruned_neutral/{chrom}/...
rule msa_split:
    input:
        bed_feats = "features/{chrom}.feat.bed",
        mask_maf = config["maf_pattern"],
        mask_fa = config["fa_pattern"]
    output:
        "pruned_neutral/{chrom}/done.txt"
    conda:
        "envs/biopython.yaml"
    log:
        "logs/msa_split/{chrom}.log"
    shell:
        """
        mkdir -p pruned_neutral/{wildcards.chrom} logs/msa_split
        msa_split {input.mask_maf} --refseq {input.mask_fa} --gap-strip ANY -q \
            --in-format MAF --features {input.bed_feats} \
            --for-features \
            --out-root pruned_neutral/{wildcards.chrom}/{wildcards.chrom} \
            > {log} 2>&1
        touch {output}
        """

# 5. Copy good alignments — safe, no deletion
rule filter_good_per_chrom:
    input:
        "pruned_neutral/{chrom}/done.txt"
    output:
        touch("filter/{chrom}.done")
    params:
        min_bases = MIN_BASES
    conda:
        "envs/biopython.yaml"
    log:
        "logs/filter_{chrom}.log"
    resources:
        mem_mb = 12000
    shell:
        """
        python3 scripts/select_and_filter_neutral.py \
            --input pruned_neutral/{wildcards.chrom} \
            --min-bases {params.min_bases} \
            --out good_alignments \
            >> {log} 2>&1 || true
        touch {output}
        """

# 6. CHECKPOINT — collects good_alignments list
checkpoint collect_good_alignments:
    input:
        expand("filter/{chrom}.done", chrom=CHROMS)
    output:
        "goodalignments.txt"
    resources: mem_mb = 1000
    shell:
        """
        mkdir -p good_alignments
        find good_alignments -name "*.fa" -type f | sort > {output}
        echo "[DEBUG] Wrote {output} with $(wc -l < {output}) entries" >&2
        touch {output}
        """

# =============================================================================
# Dynamic helpers
# =============================================================================
def get_good_regions(wildcards):
    # checkpoint has no wildcards; call get() without args
    ck = checkpoints.collect_good_alignments.get()
    listfile = ck.output[0]
    if not Path(listfile).exists():
        return []
    with open(listfile) as f:
        # Accept either full paths or basenames; return stems (basename without suffix)
        return [Path(l.strip()).stem for l in f if l.strip()]

def get_batch_count(wildcards):
    n = len(get_good_regions(wildcards))
    return max(1, (n + BATCH_SIZE - 1) // BATCH_SIZE) if n > 0 else 1

# 7. phyloFit — run batches
rule batch_phylofit:
    input:
        listfile = "goodalignments.txt",
        files = lambda wc: [
            f"good_alignments/{r}.fa"
            for r in get_good_regions(wc)[
                int(wc.i)*BATCH_SIZE : (int(wc.i)+1)*BATCH_SIZE
            ]
        ]
    output:
        directory("MODELS_HKY85/batch_{i}")
    conda:
        "envs/biopython.yaml"
    resources:
        mem_mb = 8000,
        runtime = 1800
    log:
        "logs/batch_phylofit/batch_{i}.log"
    shell:
        """
        mkdir -p {output}
        for fa in {input.files}; do
            [[ -f "$fa" ]] || continue
            r=$(basename "$fa" .fa)
            phyloFit "$fa" --tree "{TREE_TOPOLOGY}" -i FASTA --subst-mod HKY85 \
                --out-root "{output}/$r"  --init-random --precision HIGH \
                >> {log} 2>&1 || echo "FAILED $r" >> {log}
            touch "{output}/$r.mod"
        done
        """

# 8. Aggregate
rule aggregate:
    input:
        lambda wc: expand("MODELS_HKY85/batch_{i}", i=range(get_batch_count(wc)))
    output:
        "output.hky85.neutral.txt"
    log:
        "logs/aggregate.log"
    shell:
        """
        > {output}
        for d in {input}; do
            grep -H '^TREE:' "$d"/*.mod 2>/dev/null || true
        done >> {output}
        echo "Aggregated $(wc -l < {output}) models" >> {log}
        """

# 9. Parse
rule parse_neutral:
    input:
        "output.hky85.neutral.txt"
    output:
        "neutral_table.txt", "neutralset.txt", "neutral_table_full.tsv"
    conda:
        "envs/biopython.yaml"
    log:
        "logs/parse_neutral.log"
    shell:
        """
        python3 scripts/parse_neutral.py {input} {output[0]} {output[1]} \
            --full-table {output[2]} > {log} 2>&1
        """

# =============================================================================
# 10. Collect FASTA from neutralset.txt → neutral_proxy/
# =============================================================================
rule collect_neutral_proxy:
    input:
        neutralset = "neutralset.txt"
    output:
        directory("neutral_proxy")
    shell:
        """
        mkdir -p {output}
        while IFS= read -r region; do
            src="good_alignments/${{region}}"
            if [[ -f "$src" ]]; then
                cp "$src" {output}/
            else
                echo "WARNING: Not found: $src" >&2
            fi
        done < {input.neutralset}
        echo "Copied $(find {output} -name '*.fa' | wc -l) files to {output}"
        """

# =============================================================================
# 11. Cleanup
# =============================================================================
rule cleanup:
    input:
        "neutral_table.txt",
        "neutralset.txt",
        "neutral_table_full.tsv",
        "neutral_proxy"
    output:
        touch("snakemake.done")
    shell:
        """
        mkdir -p intermediate_files
        rm -rf pruned_neutral filter goodalignments.txt neutral_table.txt neutral_table_full.tsv || true
        mv -f good_alignments features \
              random.* *.chrom.sizes logs \
              output.hky85.neutral.txt MODELS_HKY85 \
              intermediate_files/ 2>/dev/null || true
        """
